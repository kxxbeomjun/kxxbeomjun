<!-- Header -->
<p align="center">
  <img src="https://capsule-render.vercel.app/api?type=waving&color=auto&height=220&section=header&text=Beomjun%20Kim&fontSize=48&fontAlign=50&fontAlignY=35&animation=twinkling" alt="header"/>
</p>

<h2 align="center">ğŸ‘‹ Hi, I'm Beomjun Kim</h2>
<p align="center">
  <em>Research Engineer @ Hyundai Motor Company, focusing on Autonomous Driving</em>
</p>

<p align="center">
  <a href="https://github.com/kxxbeomjun"><img alt="GitHub" src="https://img.shields.io/badge/GitHub-181717.svg?logo=github&logoColor=white"></a>
  <a href="https://cilab.yonsei.ac.kr/"><img alt="CILAB" src="https://img.shields.io/badge/CILAB-Yonsei-blue"></a>
  <a href="https://www.linkedin.com/in/beomjun-kim-profile/"><img alt="LinkedIn" src="https://img.shields.io/badge/LinkedIn-0A66C2.svg?logo=linkedin&logoColor=white"></a>
  <a href="#"><img alt="Notion" src="https://img.shields.io/badge/Notion-000000.svg?logo=notion&logoColor=white"></a>
</p>

---

## ğŸ¯ Research Interests
1. **Autonomous Driving**  
2. **Birdâ€™s Eye View (BEV) Networks, Knowledge Distillation, LiDAR-Camera Fusion**  
3. **Computer Vision (CV)**  

> Recent Interest: World model based temporal fusion, BEV map segmentation, Gaussian-based representations.

---

## ğŸ“ Education
- **Yonsei University**, Seoul, South Korea  
  - **M.S. Candidate** , <a href="https://cilab.yonsei.ac.kr/">CILAB</a>, <a href="https://vce.yonsei.ac.kr/vce/index.do">Mobility System Engineering</a> (2024.03 â€“ 2026.02)  
- **Yonsei University**, Seoul, South Korea  
  - **B.S.** , <a href="https://me.yonsei.ac.kr/me/index.do">Mechanical Engineering</a> (2017.03 â€“ 2024.02)

---

## ğŸš€ Careers

- **Research Engineer** at <a href="https://www.hyundaimotorgroup.com/en/main/mainRecommend/">Hyundai Motor Group</a> (2026.1 ~ Current)

---

## ğŸ› ï¸ Tech Stack
**Core**  
<p>
  <img src="https://img.shields.io/badge/Python-3776AB.svg?logo=python&logoColor=white"/>
  <img src="https://img.shields.io/badge/PyTorch-EE4C2C.svg?logo=pytorch&logoColor=white"/>
  <img src="https://img.shields.io/badge/ROS-22314E.svg?logo=ros&logoColor=white"/>
  <img src="https://img.shields.io/badge/C-00599C.svg?logo=c&logoColor=white"/>
  <img src="https://img.shields.io/badge/C++-00599C.svg?logo=c%2B%2B&logoColor=white"/>
</p>

**3D / Perception Toolchain**  
<p>
  <img src="https://img.shields.io/badge/MMDetection-2.x-orange"/>
  <img src="https://img.shields.io/badge/MMDetection3D-1.x-orange"/>
  <img src="https://img.shields.io/badge/MMCV-1.x-informational"/>
  <img src="https://img.shields.io/badge/nuScenes-devkit-blue"/>
  <img src="https://img.shields.io/badge/MinkowskiEngine-NVIDIA-76B900"/>
</p>

**Platforms**  
<p>
  <img src="https://img.shields.io/badge/Ubuntu-E95420.svg?logo=ubuntu&logoColor=white"/>
  <img src="https://img.shields.io/badge/Linux-FCC624.svg?logo=linux&logoColor=black"/>
  <img src="https://img.shields.io/badge/Windows%2011-0078D4.svg?logo=windows11&logoColor=white"/>
  <img src="https://img.shields.io/badge/macOS-000000.svg?logo=apple&logoColor=white"/>
  <img src="https://img.shields.io/badge/AWS-232F3E.svg?logo=amazonaws&logoColor=white"/>
  <img src="https://img.shields.io/badge/Google%20Drive-4285F4.svg?logo=googledrive&logoColor=white"/>
</p>
---

## ğŸ“Œ Highlights
- Developing **BEV-centric perception models** that leverage **TA-based Knowledge Distillation** to bridge the **representation gap** between Camera-only students and LiDARâ€“Camera fusion teachers.
- Exploring **World model-based temporal fusion** method for autonomous driving.
- Reproducible pipelines with version-pinned dependencies (MMCV/MMDet/MMDet3D, ME, nuScenes-devkit).

---

## ğŸ“« Contact
- Email: kbj@yonsei.ac.kr
- Lab: <a href="https://cilab.yonsei.ac.kr/">CILAB @ Yonsei</a>

---

<p align="center">
  <sub>Last updated: <!-- date -->2025-08</sub>
</p>
